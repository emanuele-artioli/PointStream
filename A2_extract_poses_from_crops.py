import argparse
import os
import cv2
import numpy as np
import pandas as pd
import torch
from ultralytics import YOLO
import ast
from tqdm import tqdm

# TODO: furthermore, we can split work per id, so that each person is processed separately. This would allow to track people.
# TODO: If more than 2 people, select the tennis players. Simplest idea is first two indices, as index reflects confidence.
# TODO: this presents itself as a very parallelizable task, can we speed it up with multiprocessing? Or is batch processing in YOLO multithreaded?

# COCO keypoint skeleton connections for YOLO pose models
SKELETON = [
    [16, 14], [14, 12], [17, 15], [15, 13], [12, 13],  # Head
    [6, 12], [7, 13], [6, 7],  # Torso
    [6, 8], [8, 10],  # Left arm
    [7, 9], [9, 11],  # Right arm
    [12, 14], [14, 16],  # Left leg
    [13, 15], [15, 17]   # Right leg
]

# Connection colors (BGR format) - color-coded by body part and side
CONNECTION_COLORS = [
    # Head connections (yellow/orange)
    (0, 165, 255),   # [16, 14] - right ear to right eye
    (0, 165, 255),   # [14, 12] - right eye to right shoulder
    (0, 255, 255),   # [17, 15] - left ear to left eye
    (0, 255, 255),   # [15, 13] - left eye to left shoulder
    (0, 200, 255),   # [12, 13] - shoulder connection
    
    # Torso (white/gray)
    (200, 200, 200), # [6, 12] - left hip to left shoulder
    (200, 200, 200), # [7, 13] - right hip to right shoulder
    (200, 200, 200), # [6, 7] - hip connection
    
    # Left arm (cyan/blue) - ACTOR'S LEFT
    (255, 255, 0),   # [6, 8] - left shoulder to left elbow
    (255, 200, 0),   # [8, 10] - left elbow to left wrist
    
    # Right arm (red/magenta) - ACTOR'S RIGHT
    (0, 0, 255),     # [7, 9] - right shoulder to right elbow
    (128, 0, 255),   # [9, 11] - right elbow to right wrist
    
    # Left leg (cyan/blue) - ACTOR'S LEFT
    (255, 150, 0),   # [12, 14] - left shoulder to left knee
    (255, 100, 0),   # [14, 16] - left knee to left ankle
    
    # Right leg (red/magenta) - ACTOR'S RIGHT
    (64, 0, 255),    # [13, 15] - right shoulder to right knee
    (128, 0, 200)    # [15, 17] - right knee to right ankle
]


def create_skeleton_image(keypoints, img_size=(512, 512)):
    """
    Create a skeleton image from keypoints.
    Keypoints are already in 512x512 crop space.
    """
    skeleton_img = np.zeros((img_size[1], img_size[0], 3), dtype=np.uint8)
    
    if not keypoints or len(keypoints) == 0:
        return skeleton_img
    
    kpts = np.array(keypoints)
    
    # Draw skeleton connections with color coding
    for i, connection in enumerate(SKELETON):
        pt1_idx, pt2_idx = connection[0] - 1, connection[1] - 1  # Convert to 0-indexed
        
        if pt1_idx < len(kpts) and pt2_idx < len(kpts):
            pt1 = tuple(kpts[pt1_idx].astype(int))
            pt2 = tuple(kpts[pt2_idx].astype(int))
            
            # Only draw if both points are valid (not [0, 0])
            if pt1 != (0, 0) and pt2 != (0, 0):
                color = CONNECTION_COLORS[i]
                cv2.line(skeleton_img, pt1, pt2, color, 3)
    
    # Draw keypoints as small neutral circles
    for kpt in kpts:
        pt = tuple(kpt.astype(int))
        if pt != (0, 0):
            cv2.circle(skeleton_img, pt, 2, (100, 100, 100), -1)
    
    return skeleton_img


def main():
    parser = argparse.ArgumentParser(description="Extract poses from masked crops and generate skeletons")
    parser.add_argument("--experiment_dir", type=str, default="/home/itec/emanuele/pointstream/experiments/20260123_122136_sam_seg", help="Path to the experiment folder generated by A1_segment_with_sam.py")
    parser.add_argument("--pose_model", type=str, default="/home/itec/emanuele/models/yolo26l-pose.pt", help="Path to the pose estimation model")
    args = parser.parse_args()

    experiment_dir = args.experiment_dir
    csv_path = os.path.join(experiment_dir, "tracking_metadata.csv")
    masked_crops_dir = os.path.join(experiment_dir, "masked_crops")
    df = pd.read_csv(csv_path)
    model = YOLO(args.pose_model)
    
    # Create skeletons output directory
    skeletons_dir = os.path.join(experiment_dir, "skeletons")
    os.makedirs(skeletons_dir, exist_ok=True)
    
    # Filter for people (class_id == 0)
    people_df = df[df['class_id'] == 0].copy()
    print(f"Found {len(people_df)} person detections out of {len(df)} total detections.")

    pose_results = []
    
    for _, row in tqdm(people_df.iterrows(), total=len(people_df), desc="Extracting poses"):
        frame_idx = row['frame_index']
        det_id = row['id']
        bbox = ast.literal_eval(row['bbox']) if isinstance(row['bbox'], str) else row['bbox']
        
        # Load masked crop
        crop_path = os.path.join(masked_crops_dir, f"id{det_id}", f"{frame_idx:05d}.png")
        if not os.path.exists(crop_path):
            continue
        crop = cv2.imread(crop_path)
        if crop is None:
            continue

        # Run pose estimation on the 512x512 masked crop
        results = model.predict(crop, conf=0.25, iou=0.45, device='cuda', half=True, verbose=False)
        for res in results:
            if res.keypoints is not None and len(res.keypoints) > 0:
                keypoints = res.keypoints[0].cpu().numpy()
                keypoints_list = keypoints.xy[0].tolist()

                pose_results.append({
                    "frame_index": frame_idx,
                    "detection_id": det_id,
                    "bbox": bbox,
                    "keypoints": keypoints_list
                })
                
                # Create and save skeleton image
                skeleton_img = create_skeleton_image(keypoints_list)
                id_subfolder = os.path.join(skeletons_dir, f"id{det_id}")
                os.makedirs(id_subfolder, exist_ok=True)
                skeleton_path = os.path.join(id_subfolder, f"{frame_idx:05d}.png")
                cv2.imwrite(skeleton_path, skeleton_img)

    # Save pose CSV
    if pose_results:
        results_df = pd.DataFrame(pose_results)
        output_csv = os.path.join(experiment_dir, "pose_metadata.csv")
        results_df.to_csv(output_csv, index=False)
        print(f"Saved pose metadata to {output_csv}")
        print(f"Skeleton images saved to: {skeletons_dir}")
    else:
        print("No person detections processed.")

if __name__ == "__main__":
    main()
