import argparse
import os
import cv2
import numpy as np
import pandas as pd
import torch
from ultralytics import YOLO
import ast
from tqdm import tqdm

# TODO: We get masks and frames from segmentation. Crop and mask images before pose estimation.
# TODO: furthermore, we can split work per id, so that each person is processed separately. This would allow to track people.
# TODO: If more than 2 people, select the tennis players. Simplest idea is first two indices, as index reflects confidence.
# TODO: this presents itself as a very parallelizable task, can we speed it up with multiprocessing? Or is batch processing in YOLO multithreaded?

def main():
    parser = argparse.ArgumentParser(description="Extract poses from person crops")
    parser.add_argument("--experiment_dir", type=str, default="/home/itec/emanuele/pointstream/experiments/20260123_122136_sam_seg", help="Path to the experiment folder generated by segment_with_yolo.py")
    parser.add_argument("--pose_model", type=str, default="/home/itec/emanuele/models/yolo11l-pose.pt", help="Path to the pose estimation model")
    args = parser.parse_args()

    experiment_dir = args.experiment_dir
    csv_path = os.path.join(experiment_dir, "tracking_metadata.csv")
    frames_dir = os.path.join(experiment_dir, "frames")
    df = pd.read_csv(csv_path)
    model = YOLO(args.pose_model)
    
    # Filter for people (class_id == 0)
    people_df = df[df['class_id'] == 0].copy()
    print(f"Found {len(people_df)} person detections out of {len(df)} total detections.")

    pose_results = []
    unique_frames = people_df['frame_index'].unique()
    unique_frames.sort()
    
    for frame_idx in unique_frames:
        frame_detections = people_df[people_df['frame_index'] == frame_idx]
        
        # Load frame
        frame_filename = os.path.join(frames_dir, f"frame{frame_idx:05d}.png")
        frame = cv2.imread(frame_filename)
        
        # Process each detection in the frame
        for _, row in frame_detections.iterrows():
            bbox = ast.literal_eval(row['bbox'])  # [x1, y1, x2, y2]
            x1, y1, x2, y2 = map(int, bbox)
            crop = frame[y1:y2, x1:x2]

            # Run pose estimation
            results = model.predict(crop, conf=0.25, iou=0.45, device='cuda', half=True)
            for res in results:
                if res.keypoints is not None and len(res.keypoints) > 0:
                    keypoints = res.keypoints[0].cpu().numpy()
                    keypoints_list = keypoints.xy[0].tolist()

                    pose_results.append({
                        "frame_index": frame_idx,
                        "detection_id": row['id'],
                        "bbox": bbox,
                        "keypoints": keypoints_list
                    })

    # Save new CSV
    if pose_results:
        results_df = pd.DataFrame(pose_results)
        output_csv = os.path.join(experiment_dir, "pose_metadata.csv")
        results_df.to_csv(output_csv, index=False)
        print(f"Saved pose metadata to {output_csv}")
    else:
        print("No person detections processed.")

if __name__ == "__main__":
    main()
