# PointStream Configuration File
# This file contains all configurable parameters for the PointStream pipeline.
# Each parameter is accompanied by a comment explaining its purpose and how
# tuning it can affect the performance (speed) and quality of the output.

[scene_detection]
# Configures the scene detection algorithm.

# detector_type: Specifies the algorithm for detecting scene changes.
# - 'content': Default, fast, good for general use.
# - 'adaptive': Adapts to changing video pace, good for dynamic content.
# - 'threshold': Detects fades and dissolves.
# - 'hash': Fastest, uses perceptual hashing, good for near-duplicate detection.
# - 'multi': Combines multiple detectors for higher accuracy at the cost of speed.
detector_type = multi

# threshold: The sensitivity of the scene detector.
# - Higher values: More sensitive, detects more scene cuts (may result in shorter scenes).
# - Lower values: Less sensitive, detects fewer scene cuts (may result in longer scenes).
# Affects: Quality.
threshold = 27.0

# min_scene_len: The minimum number of frames a scene must have.
# Scenes shorter than this will be merged with adjacent scenes.
# Affects: Quality.
min_scene_len = 10

# luma_only: If true, scene detection is based only on brightness changes.
# - true: Faster, but may miss cuts that are primarily color-based.
# - false: More accurate, considers color information.
# Affects: Speed, Quality.
luma_only = false

# enable_downscaling: If true, frames are downscaled before scene detection.
# This significantly improves performance at a minor cost to accuracy.
# Affects: Speed.
enable_downscaling = true

# downscale_factor: The factor by which to downscale frames for detection.
# A factor of 4 means the frame will be 1/4 of its original size.
# - Higher values: Faster detection, but less accurate.
# - 0: Auto-calculates a suitable factor.
# Affects: Speed, Quality.
downscale_factor = 4

# use_stats_manager: Caches frame metrics to speed up repeated processing of the same video.
# - true: Faster on subsequent runs of the same video.
# - false: Recommended for production to get accurate performance metrics on every run.
# Affects: Speed (on repeated runs).
use_stats_manager = false

# multi_detector_threshold: When using 'multi' detector, this is the minimum combined weight for a cut to be registered.
# Affects: Quality.
multi_detector_threshold = 1.0

# content_weight, adaptive_weight, histogram_weight, hash_weight:
# The weight of each detector when using 'multi' mode.
# Higher weights give a detector more influence on the final decision.
# Affects: Quality.
content_weight = 1.0
adaptive_weight = 0.8
histogram_weight = 0.6
hash_weight = 0.9

# adaptive_window_frames: The number of frames the 'adaptive' detector uses for its rolling average.
# Affects: Quality.
adaptive_window_frames = 60

# histogram_bins: The number of bins to use for the 'histogram' detector.
# Affects: Quality.
histogram_bins = 256

# hash_size: The size of the perceptual hash for the 'hash' detector.
# Affects: Quality.
hash_size = 8

# interpolation_method: The method used for downscaling frames.
# 'linear' is a good balance of speed and quality.
# Affects: Speed, Quality.
interpolation_method = linear

# batch_size: The number of frames to process in each batch for real-time simulation.
# Affects: Memory usage, Latency.
batch_size = 100

# overlap_frames: The number of frames to overlap between batches to avoid missing cuts at batch boundaries.
# Affects: Speed, Quality.
overlap_frames = 10

# default_max_frames: The maximum number of frames a scene can have before a cut is forced.
# Prevents extremely long scenes.
# Affects: Quality.
default_max_frames = 200

# default_output_pattern: The naming pattern for output directories when saving scenes.
default_output_pattern = {input_stem}_scenes

# min_scene_duration: The minimum duration in seconds for a scene to be considered valid.
# Affects: Quality.
min_scene_duration = 0.5

# verify_output_files: If true, checks if the encoded video files are valid.
# Affects: Speed.
verify_output_files = true

# check_video_integrity: If true, uses ffmpeg to check the integrity of encoded files.
# Affects: Speed.
check_video_integrity = true

[encoding]
# Configures video and audio encoding settings, primarily for saving complex scenes.

# video_codec: The video codec to use for encoding.
# - 'libsvtav1': AV1 codec, excellent compression, but slow.
# - 'libx265': H.265/HEVC, great compression, widely supported.
# - 'libx264': H.264/AVC, very fast, best compatibility.
# - 'libvpx-vp9': VP9 codec, good compression, used by YouTube.
# Affects: Speed, Quality, File Size.
video_codec = libsvtav1

# audio_codec: The audio codec to use. 'libopus' is a high-quality, efficient choice.
# Set to empty to disable audio encoding.
# Affects: Quality, File Size.
audio_codec = libopus

# container_format: The container for the encoded video (e.g., mp4, mkv).
container_format = mp4

# crf: Constant Rate Factor. Controls the quality and file size.
# - Lower values: Higher quality, larger file size.
# - Higher values: Lower quality, smaller file size.
# A good range for AV1 is 25-40. For x264/x265, 18-28.
# Affects: Quality, File Size.
crf = 30

# panorama_video_encoding: If true, saves the panorama background as a video for debugging purposes.
# Uses the same encoding parameters as complex scenes.
# Affects: Disk usage, Debugging capability.
panorama_video_encoding = true

# panorama_quality: JPEG quality for saving panorama images (1-100).
# - Higher values: Better image quality, larger file size.
# - Lower values: Lower image quality, smaller file size.
# Affects: Panorama image quality, File Size.
panorama_quality = 50

# preset: Encoding speed preset.
# - Slower presets: Better compression (smaller file size for the same quality), but much slower.
# - Faster presets: Faster encoding, but less efficient compression.
# For AV1, presets are 0-12 (slowest to fastest). For x264/x265, e.g., 'slow', 'medium', 'fast'.
# Affects: Speed, File Size.
preset = 6

# pixel_format: The pixel format for color space information. 'yuv420p' is standard for web video.
# Affects: Compatibility.
pixel_format = yuv420p

# color_range, color_space: Color standards for video. 'tv' and 'bt709' are common defaults.
# Affects: Compatibility.
color_range = tv
color_space = bt709

# audio_bitrate: The bitrate for audio encoding. '128k' is good for stereo.
# Affects: Quality, File Size.
audio_bitrate = 128k

# audio_sample_rate, audio_channels: Audio properties. 48000 Hz and 2 channels (stereo) are standard.
# Affects: Quality.
audio_sample_rate = 48000
audio_channels = 2

# ffmpeg_binary: Path to the FFmpeg executable.
ffmpeg_binary = ffmpeg

# ffmpeg_timeout: Timeout in seconds for FFmpeg encoding processes.
# Affects: Stability.
ffmpeg_timeout = 300

# ffmpeg_threads: Number of threads for FFmpeg to use.
# - 0: Auto-detect.
# Affects: Speed.
ffmpeg_threads = 0

# faststart: If true, moves metadata to the beginning of the file for faster web streaming.
# Affects: Compatibility.
faststart = true

# continue_on_error: If true, the pipeline will continue even if a scene fails to encode.
# Affects: Stability.
continue_on_error = false

# retry_failed: Number of times to retry a failed encoding.
# Affects: Stability.
retry_failed = 1

# extra_input_args, extra_output_args: Advanced FFmpeg options. Use with caution.
extra_input_args = []
extra_output_args = []

# backend: The video processing backend for reading frames.
# - 'auto': Automatically selects the best available backend.
# - 'pyav': Generally faster and more reliable than opencv.
# - 'opencv': Default fallback.
# Affects: Speed, Stability.
backend = auto

# scene_filename_pattern, scene_list_filename, metadata_filename: Naming patterns for output files.
scene_filename_pattern = scene_{number:04d}.{extension}
scene_list_filename = scene_list.txt
metadata_filename = metadata.json

# export_metadata: If true, a detailed metadata JSON file is saved for each scene.
export_metadata = true
include_timestamps = true
include_file_info = true
include_encoding_info = true

# min_file_size_kb, max_file_size_mb: Quality control checks for encoded files.
min_file_size_kb = 10
max_file_size_mb = 1000

[segmentation]
# Configures the object segmentation model (YOLO).

# yolo_model: Path to the YOLO model file.
yolo_model = /home/itec/emanuele/models/yoloe-11s-seg-pf.pt

# confidence_threshold: The minimum confidence score for an object detection to be considered valid.
# - Higher values: Fewer, but more reliable detections.
# - Lower values: More detections, but potentially more false positives.
# Affects: Quality.
confidence_threshold = 0.25

# iou_threshold: Intersection over Union threshold for Non-Maximum Suppression (NMS).
# Used to filter out overlapping bounding boxes.
# Affects: Quality.
iou_threshold = 0.7

# max_objects_per_frame: The maximum number of objects to detect in a single frame.
# Affects: Speed, Quality.
max_objects_per_frame = 10

# device: The device to run the YOLO model on. 'cuda' for GPU, 'cpu' for CPU.
# 'cuda' is significantly faster.
# Affects: Speed.
device = cuda

# agnostic_nms: If true, NMS is class-agnostic.
agnostic_nms = true

# yolo_image_size: The size to which images are resized before being fed to the YOLO model.
# Must match the model's training size.
# Affects: Quality.
yolo_image_size = 1280

# yolo_half_precision: If true, uses half-precision (FP16) for inference.
# Can speed up inference on compatible GPUs (NVIDIA Volta, Turing, Ampere).
# Affects: Speed.
yolo_half_precision = true

# yolo_stream: If true, uses CUDA streams for more efficient processing on the GPU.
# Affects: Speed.
yolo_stream = true

# classes: A list of specific class IDs to detect. If empty, all classes are detected.
classes = []

# selection_strategy: How to select objects if the number exceeds max_objects_per_frame.
# 'confidence' selects the objects with the highest confidence scores.
selection_strategy = confidence

# min_object_area: The minimum area in pixels for a detected object to be considered valid.
# Filters out very small, likely irrelevant objects.
# Affects: Quality.
min_object_area = 100

# frame_skip: The number of frames to skip between segmentation runs.
# - 0 or 1: Process every frame (most accurate, slowest).
# - Higher values: Skips frames, faster but may miss objects.
# Affects: Speed, Quality.
frame_skip = 1

# diffusion_model: The diffusion model to use for background reconstruction inpainting.
# Default is Stable Diffusion inpainting model from RunwayML.
# Affects: Quality, Speed.
diffusion_model = runwayml/stable-diffusion-inpainting

# diffusion_inference_steps: Number of denoising steps for diffusion inpainting.
# Higher values produce better quality but take longer.
# Affects: Quality, Speed.
diffusion_inference_steps = 20

# diffusion_guidance_scale: How much the model should follow the text prompt.
# Higher values make the output follow the prompt more closely.
# Affects: Quality.
diffusion_guidance_scale = 7.5

# diffusion_prompt: Text prompt for diffusion inpainting to guide background reconstruction.
# Should describe the desired background appearance.
# Affects: Quality.
diffusion_prompt = background

[stitching]
# Configures the image stitching process for creating panoramas.

# feature_detector: The algorithm to use for detecting keypoints in frames.
# - 'orb': Very fast, but less robust to changes in scale and rotation.
# - 'sift': More accurate and robust, but significantly slower and may have patent issues.
# Affects: Speed, Quality.
feature_detector = sift

# This tells the algorithm the maximum number of "best" features to identify in a single image.
# It doesn't look for every possible feature, just the top N most unique ones.
# More features can lead to a more accurate match but will slow down the process significantly.
# Fewer features is faster but increases the risk of not finding enough matching points to stitch the images.
sift_nfeatures = 1000
# ORB features are "cheaper" and less descriptive than SIFT features. 
# To compensate for their lower quality, we need a larger number of them.
orb_nfeatures = 5000

# This is the absolute minimum number of matching feature pairs required to even attempt to calculate a homography. 
# Mathematically, you need at least 4 corresponding points to solve for the perspective transformation between two planes. 
# If the algorithm can't find at least N plausible matches, it assumes the images don't overlap and gives up.
min_match_count = 4

# This is the margin of error for voting in one RANSAC (RANdom SAmple Consensus) round. 
# RANSAC is a voting process to separate good matches (inliers) from bad matches (outliers).
# When testing a homography, we take a point from the first image, apply the transformation, and see where it lands in the second image. 
# If it lands within an N pixel radius of its matched partner, we count it as a "vote" or an inlier.
ransac_reproj_threshold = 10

# This is the number of voting rounds. 
# The algorithm will randomly select min_match_count matches and calculate a test homography up to N times to find the best possible consensus. 
# More iterations increase the chance of finding the optimal result but take more time.
ransac_max_iters = 500

# This sets the target confidence level. 
# The algorithm will try to run enough iterations to be N% certain that the winning homography is the correct one. 
# This parameter works together with ransac_max_iters.
ransac_confidence = 0.8

# This is a crucial quality check. 
# After RANSAC finds the best homography, it checks what percentage of the original matches were inliers. 
# This parameter requires that at least X% of the matches support the final homography. 
# If the ratio is lower, it means the match is unreliable (too many outliers), and the algorithm will reject the pair of images. 
# This prevents stitching images that don't actually overlap.
min_inlier_ratio = 0.1

# This handles the case where the camera didn't move between frames. 
# If there's no movement, the "transformation" is essentially nothing (an identity matrix). 
# This parameter checks if the calculated homography is extremely close to an identity matrix. 
# If it is, the frame is ignored because it adds no new information to the panorama.
static_homography_threshold = 0.05

# If true, applies a smoothing filter to the sequence of homography matrices.
# This helps to reduce jitter in the final reconstructed video.
# Affects: Quality.
enable_homography_smoothing = true

# The size of the moving average window for homography smoothing.
# A larger window results in smoother motion but can introduce some lag.
# Affects: Quality.
smoothing_window_size = 5

# use_background_reconstruction: If true, attempts to reconstruct the background behind segmented objects.
# Affects: Quality.
use_background_reconstruction = true

# enable_panorama_cleanup: If true, attempts to inpaint black areas in the final panorama.
# Affects: Quality.
enable_panorama_cleanup = false

# cleanup_black_threshold: The threshold for detecting black pixels for cleanup.
# Affects: Quality.
cleanup_black_threshold = 10

# exclude_border_black_areas: If true, does not inpaint black areas that touch the panorama border.
# Affects: Quality.
exclude_border_black_areas = false

# border_exclusion_width: The width of the border exclusion zone in pixels.
# Affects: Quality.
border_exclusion_width = 10

# inpaint_radius: The radius of the neighborhood used for inpainting.
# Affects: Quality.
inpaint_radius = 5

[keypoints]
# Configures keypoint detection for different object types.

# human_confidence_threshold, animal_confidence_threshold:
# Minimum confidence for detected human/animal keypoints to be considered valid.
# Affects: Quality.
human_confidence_threshold = 0.3
animal_confidence_threshold = 0.3

# canny_low_threshold, canny_high_threshold, canny_kernel_size:
# Parameters for Canny edge detection, used for 'other' objects.
# Affects: Quality.
canny_low_threshold = 50
canny_high_threshold = 150
canny_kernel_size = 3

# corner_max_corners, corner_quality_level, corner_min_distance:
# Parameters for corner detection (e.g., Shi-Tomasi), used for 'other' objects.
# Affects: Quality.
corner_max_corners = 25
corner_quality_level = 0.01
corner_min_distance = 10

# MMPose model configurations
# Specifies the model alias or path to the config file for MMPose.
# 'human' and 'animal' are default aliases in MMPose.
human_model_config = human
human_model_checkpoint =
animal_model_config = animal
animal_model_checkpoint =

[semantic]
# Configures semantic classification of objects.

# model_name: The name of the sentence-transformer model to use for classification.
model_name = all-MiniLM-L6-v2

# human_threshold, animal_threshold: The similarity score thresholds for classifying an object as human or animal.
# Affects: Quality.
human_threshold = 0.75
animal_threshold = 0.65

# similarity_metric: The metric used to compare object class names with semantic categories.
# 'cosine' is standard for sentence transformers.
similarity_metric = cosine

[duplicate_filter]
# Configures the filtering of duplicate object detections.

# iou_threshold: The IoU threshold above which two bounding boxes are considered duplicates.
# Affects: Quality.
iou_threshold = 0.7

# confidence_weight, area_weight: Weights for combining confidence and area when resolving duplicates.
# Affects: Quality.
confidence_weight = 0.6
area_weight = 0.4

[saver]
# Configures how output files are saved.

# video_codec, video_quality, video_preset, container_format, ffmpeg_binary, ffmpeg_threads:
# These parameters are used for saving complex scenes as video.
# They mirror the settings in the [encoding] section but are specific to the saver component.
# See the [encoding] section for detailed explanations.
video_codec = libx264
video_quality = 23
video_preset = medium
container_format = mp4
ffmpeg_binary = ffmpeg
ffmpeg_threads = 0

# image_format: The format for saving individual object images. 'png' is required for transparency.
image_format = png

# image_quality: The quality setting for saved images (e.g., for JPEG).
image_quality = 95

# save_individual_objects: If true, cropped images of each detected object are saved.
save_individual_objects = true

# save_metadata: If true, a metadata file is saved for each scene.
save_metadata = true

# save_debug_data: If true, extra debug information is included in the saved metadata.
save_debug_data = true

[logging]
# Configures logging and progress reporting.

# log_level: The minimum level of log messages to display (DEBUG, INFO, WARNING, ERROR).
log_level = INFO

# log_to_file: If true, logs are written to a file.
log_to_file = true

# log_filename_pattern: The naming pattern for the log file.
log_filename_pattern = {input_stem}_processing.log

# verbose_ffmpeg: If true, prints detailed FFmpeg output on error.
verbose_ffmpeg = false

# collect_statistics: If true, collects and saves detailed performance statistics.
collect_statistics = true

# statistics_filename: The name of the file to save performance statistics to.
statistics_filename = processing_stats.json

[pipeline]
# Configures the overall pipeline behavior.

# num_workers: The number of worker processes to use for parallel processing.
# Affects: Speed.
num_workers = 1

# max_parallel_scenes: The maximum number of scenes to process in parallel.
# Affects: Speed, Memory usage.
max_parallel_scenes = 1

# sequential_mode: If true, forces the pipeline to run sequentially, overriding parallel settings.
# Useful for debugging.
sequential_mode = true

# enable_caching: If true, enables caching of intermediate results to speed up repeated processing.
# Affects: Speed (on repeated runs), Disk usage.
enable_caching = true

# cache_dir: The directory to store cached data.
cache_dir = ./cache

[muxer]
# Configures the compression of metadata files.

# compression_level: The gzip compression level (1-9).
# - Higher values: Better compression, but slower.
# Affects: Speed, File Size.
compression_level = 6

# use_binary_format: If true, uses a compact binary format (pickle+gzip) for metadata.
# If false, uses JSON+gzip.
# Affects: File Size.
use_binary_format = true

# remove_debug_data: If true, removes debug information from metadata before compression.
# Affects: File Size.
remove_debug_data = true

# float_precision: The number of decimal places to keep for floating-point numbers in metadata.
# Affects: File Size, Quality (of metadata).
float_precision = 6

[demuxer]
# Configures the decompression of metadata files.

# restore_numpy_arrays: If true, converts lists in metadata back to numpy arrays.
restore_numpy_arrays = true

# validate_homographies: If true, checks the validity of homography matrices during decompression.
validate_homographies = true

[reconstruction]
# Configures the client-side video reconstruction process.

# background_blending: The method for blending reconstructed backgrounds.
# 'gaussian' provides a smoother transition.
# Affects: Quality.
background_blending = gaussian

# background_blur_kernel: The size of the kernel for Gaussian blur blending.
# Affects: Quality.
background_blur_kernel = 5

# background_interpolation: Interpolation method for transforming the background panorama.
# 'bilinear' is a good balance between speed and quality.
# Affects: Speed, Quality.
background_interpolation = bilinear

# homography_smoothing: If true, applies smoothing to homography matrices to reduce jitter in the background.
# Affects: Quality.
homography_smoothing = true

# temporal_consistency: If true, attempts to enforce temporal consistency between frames for a smoother video.
# Affects: Quality.
temporal_consistency = true

# keypoint_interpolation: The method for interpolating keypoints between frames.
# 'cubic' provides a smoother, more natural motion.
# Affects: Quality.
keypoint_interpolation = cubic

# object_smoothing: If true, applies smoothing to the motion of reconstructed objects.
# Affects: Quality.
object_smoothing = true

# motion_prediction: If true, uses motion prediction to handle occluded or missing keypoints.
# Affects: Quality.
motion_prediction = true

# occlusion_handling: If true, enables specific logic to handle cases where objects are occluded.
# Affects: Quality.
occlusion_handling = true

[models]
# Configuration for the generative models used in reconstruction.

# model_type: The type of generative model to use.
# 'cgan': Conditional Generative Adversarial Network.
# 'vae': Variational Autoencoder.
# 'diffusion': Denoising Diffusion Probabilistic Models (can be slow but high quality).
# Affects: Speed, Quality, Memory usage.
model_type = cgan

# device: The device to run the models on ('cuda' for GPU, 'cpu' for CPU).
# 'cuda' is significantly faster.
# Affects: Speed.
device = cuda

# batch_size: The number of objects to process in a single batch during generation.
# Higher values can be faster on GPU but use more memory.
# Affects: Speed, Memory usage.
batch_size = 8

# num_workers: The number of worker threads for loading data.
# Affects: Speed.
num_workers = 4

# human_model_path, animal_model_path, other_model_path:
# Paths to the pre-trained generative models for different object categories.
human_model_path = ./models/human_cgan.pth
animal_model_path = ./models/animal_cgan.pth
other_model_path = ./models/other_cgan.pth

# human_input_size, animal_input_size, other_input_size:
# The image size (in pixels) that the models expect as input.
# Must match the model's training configuration.
# Affects: Quality.
human_input_size = 256
animal_input_size = 256
other_input_size = 256

# human_keypoint_channels, animal_keypoint_channels, other_feature_channels:
# The number of input channels for the models, corresponding to keypoints or other features.
# Must match the model's architecture.
human_keypoint_channels = 17
animal_keypoint_channels = 20
other_feature_channels = 50

# human_pose_confidence_threshold, animal_pose_confidence_threshold, other_confidence_threshold:
# The minimum confidence threshold for input features (e.g., keypoints) to be used by the model.
# Affects: Quality.
human_pose_confidence_threshold = 0.3
animal_pose_confidence_threshold = 0.3
other_confidence_threshold = 0.3

[training]
# Parameters for training the generative models.

# learning_rate: The learning rate for the optimizer.
# Affects: Training speed, Stability.
learning_rate = 0.0002

# beta1, beta2: Parameters for the Adam optimizer.
# Affects: Training stability.
beta1 = 0.5
beta2 = 0.999

# num_epochs: The total number of training epochs.
# Affects: Training time, Quality.
num_epochs = 200

# save_checkpoint_every: The frequency (in epochs) for saving model checkpoints.
save_checkpoint_every = 10

# validation_split: The fraction of the training data to use for validation.
validation_split = 0.1

# adversarial_loss_weight, reconstruction_loss_weight, perceptual_loss_weight, temporal_consistency_weight:
# Weights for the different components of the loss function.
# Tuning these affects the trade-off between different aspects of reconstruction quality.
# Affects: Quality.
adversarial_loss_weight = 1.0
reconstruction_loss_weight = 100.0
perceptual_loss_weight = 10.0
temporal_consistency_weight = 5.0

# enable_augmentation: If true, applies data augmentation during training.
# Affects: Model robustness, Quality.
enable_augmentation = true

# horizontal_flip, rotation_range, scale_range, brightness_range:
# Parameters for data augmentation.
# Affects: Model robustness, Quality.
horizontal_flip = true
rotation_range = 15
scale_range = 0.1
brightness_range = 0.2

[video_reconstruction]
# Settings for assembling the final video output.

# fps: The framerate of the reconstructed video.
# This is now a fallback value if the framerate is not provided in the scene metadata.
# Affects: Smoothness of motion.
fps = 25.0

# video_codec: The video codec to use for encoding the reconstructed video.
# See the [encoding] section in the root config.ini for more details.
# Affects: Speed, Quality, File Size.
video_codec = libx264

# video_quality: The quality setting (CRF) for the video codec.
# See the [encoding] section in the root config.ini for more details.
# Affects: Quality, File Size.
video_quality = 23

# video_preset: The encoding speed preset.
# See the [encoding] section in the root config.ini for more details.
# Affects: Speed, File Size.
video_preset = medium

# container_format: The container for the final video file.
container_format = mp4

# enable_quality_metrics: If true, enables the computation of quality assessment metrics.
# Affects: Speed.
enable_quality_metrics = true

# compute_ssim, compute_psnr, compute_lpips, compute_vmaf:
# Specific quality metrics to compute. VMAF is very slow and requires an external installation.
# Affects: Speed.
compute_ssim = true
compute_psnr = true
compute_lpips = true
compute_vmaf = false

# temporal_smoothing: If true, applies a smoothing filter across frames to reduce flicker.
# Affects: Quality.
temporal_smoothing = true

# smoothing_window: The number of frames to use in the temporal smoothing window.
# Affects: Quality.
smoothing_window = 3

# motion_compensation: If true, uses motion compensation during temporal smoothing.
# Affects: Speed, Quality.
motion_compensation = true

[client]
# General client-specific settings.

# max_parallel_scenes: The maximum number of scenes to reconstruct in parallel.
# Affects: Speed, Memory usage.
max_parallel_scenes = 2

# enable_caching: If true, enables caching of intermediate reconstruction data.
# Affects: Speed (on repeated runs), Disk usage.
enable_caching = true

# cache_dir: The directory to store cached client data.
cache_dir = ./cache/client

# cleanup_temp_files: If true, temporary files created during reconstruction are deleted.
cleanup_temp_files = true

# memory_optimization: If true, enables optimizations to reduce memory usage, possibly at the cost of speed.
memory_optimization = true
